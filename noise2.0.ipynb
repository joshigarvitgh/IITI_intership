{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction of data and prediction of  base Parameters for Noise Isolation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import random\n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=np.linspace(1, 10, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fuctions\n",
    "\n",
    "#linear\n",
    "def linear(m,c):\n",
    "    y=m*x+c\n",
    "    return y\n",
    "\n",
    "#gaussian\n",
    "def gaussian(mu,sigma,a):\n",
    "    gu=((a * np.exp( - (x - mu)**2 / (2 * sigma**2) )))\n",
    "    return gu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# genration of signals\n",
    "#noisy \n",
    "def calcN():\n",
    "    m=random.uniform(.1,2)\n",
    "    mu=random.uniform(3,6)\n",
    "    sigma=random.uniform(.1,2)\n",
    "    c=random.uniform(0,3)\n",
    "    a=random.uniform(2,6)\n",
    "    noise=(np.random.normal(0,.1,150))\n",
    "    li=linear(m,c)\n",
    "    gaus=gaussian(mu,sigma,a)\n",
    "    sig=li+gaus+noise\n",
    "    return sig,m,mu,sigma,c,a,x\n",
    "#without Noise\n",
    "def calcC():\n",
    "    m=random.uniform(0,2)\n",
    "    mu=random.uniform(0,6)\n",
    "    sigma=random.uniform(.1,2)\n",
    "    c=random.uniform(0,3)\n",
    "    a=random.uniform(0,6)\n",
    "    noise=(np.random.normal(0,.1,150))\n",
    "    li=linear(m,c)\n",
    "    gaus=gaussian(mu,sigma,a)\n",
    "    sig=li+gaus\n",
    "    return sig,m,mu,sigma,c,a,x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#without noise\n",
    "signal=[ calcC() for i in range(4000)]\n",
    "#with noise\n",
    "signal2=[ calcN() for i in range(2000)]\n",
    "#signal is a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#genarate dataframes without noise\n",
    "df = pd.DataFrame(signal)\n",
    "signals=(df[0])\n",
    "m=df[1]\n",
    "mu=df[2]\n",
    "sigma=df[3]\n",
    "c=df[4]\n",
    "a=df[5]\n",
    "x=df[6]\n",
    "\n",
    "#genarate dataframes with noise\n",
    "df2 = pd.DataFrame(signal2)\n",
    "signals2=(df2[0])\n",
    "m2=df2[1]\n",
    "mu2=df2[2]\n",
    "sigma2=df2[3]\n",
    "c2=df2[4]\n",
    "a2=df2[5]\n",
    "x2=df2[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#proper Array conversion \n",
    "#without noise\n",
    "signw=[[ signals[i][j] for j in range(150)] for i in range(4000)]\n",
    "\n",
    "#with noise\n",
    "signw2=[[ signals2[i][j] for j in range(150)] for i in range(2000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#form a pandas dataframe without noise\n",
    "data={'signal':signw,\n",
    "        'mu':df[2], \n",
    "        'sigma':df[3], \n",
    "        'amplitude':df[5],\n",
    "        'slope':df[1],\n",
    "        'constant':df[4]\n",
    "        }\n",
    "DatasetC =pd.DataFrame(data,columns = ['signal', 'mu', 'sigma', 'amplitude','slope','constant'])\n",
    "\n",
    "#form a pandas dataframe with noise\n",
    "data={'signal':signw2,\n",
    "        'mu':df2[2], \n",
    "        'sigma':df2[3], \n",
    "        'amplitude':df2[5],\n",
    "        'slope':df2[1],\n",
    "        'constant':df2[4]\n",
    "        }\n",
    "DatasetN =pd.DataFrame(data,columns = ['signal', 'mu', 'sigma', 'amplitude','slope','constant'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save data to CSV\n",
    "#Dataset2.to_csv('signal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signal</th>\n",
       "      <th>mu</th>\n",
       "      <th>sigma</th>\n",
       "      <th>amplitude</th>\n",
       "      <th>slope</th>\n",
       "      <th>constant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[3.03617636021, 3.12354553282, 3.21378533091, ...</td>\n",
       "      <td>3.525113</td>\n",
       "      <td>1.044436</td>\n",
       "      <td>3.041374</td>\n",
       "      <td>1.045172</td>\n",
       "      <td>1.827396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[6.20444455022, 6.25529865883, 6.29917730153, ...</td>\n",
       "      <td>0.733320</td>\n",
       "      <td>1.319496</td>\n",
       "      <td>3.659098</td>\n",
       "      <td>1.450103</td>\n",
       "      <td>1.169217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[6.0809705668, 6.09528944307, 6.10144609765, 6...</td>\n",
       "      <td>0.630079</td>\n",
       "      <td>0.742606</td>\n",
       "      <td>2.198992</td>\n",
       "      <td>1.615962</td>\n",
       "      <td>2.522602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[3.46961415012, 3.58488213867, 3.70015100252, ...</td>\n",
       "      <td>3.556370</td>\n",
       "      <td>0.472827</td>\n",
       "      <td>2.177071</td>\n",
       "      <td>1.908310</td>\n",
       "      <td>1.561303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[4.93825042596, 5.01506772731, 5.091087768, 5....</td>\n",
       "      <td>0.246739</td>\n",
       "      <td>1.687690</td>\n",
       "      <td>0.911029</td>\n",
       "      <td>1.496713</td>\n",
       "      <td>2.616878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              signal        mu     sigma  \\\n",
       "0  [3.03617636021, 3.12354553282, 3.21378533091, ...  3.525113  1.044436   \n",
       "1  [6.20444455022, 6.25529865883, 6.29917730153, ...  0.733320  1.319496   \n",
       "2  [6.0809705668, 6.09528944307, 6.10144609765, 6...  0.630079  0.742606   \n",
       "3  [3.46961415012, 3.58488213867, 3.70015100252, ...  3.556370  0.472827   \n",
       "4  [4.93825042596, 5.01506772731, 5.091087768, 5....  0.246739  1.687690   \n",
       "\n",
       "   amplitude     slope  constant  \n",
       "0   3.041374  1.045172  1.827396  \n",
       "1   3.659098  1.450103  1.169217  \n",
       "2   2.198992  1.615962  2.522602  \n",
       "3   2.177071  1.908310  1.561303  \n",
       "4   0.911029  1.496713  2.616878  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DatasetC[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signal</th>\n",
       "      <th>mu</th>\n",
       "      <th>sigma</th>\n",
       "      <th>amplitude</th>\n",
       "      <th>slope</th>\n",
       "      <th>constant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2.41228380224, 2.48438925791, 2.79660720304, ...</td>\n",
       "      <td>5.572910</td>\n",
       "      <td>1.769763</td>\n",
       "      <td>4.919575</td>\n",
       "      <td>0.948330</td>\n",
       "      <td>1.317692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2.27442932107, 2.45701398407, 2.54609334696, ...</td>\n",
       "      <td>3.511228</td>\n",
       "      <td>0.708826</td>\n",
       "      <td>2.645008</td>\n",
       "      <td>1.308834</td>\n",
       "      <td>1.033855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[3.14018284117, 3.0731935328, 3.42088457425, 3...</td>\n",
       "      <td>5.659399</td>\n",
       "      <td>1.770733</td>\n",
       "      <td>4.422514</td>\n",
       "      <td>0.613850</td>\n",
       "      <td>2.511995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[3.24357931103, 3.43598322601, 3.2900182282, 3...</td>\n",
       "      <td>5.389867</td>\n",
       "      <td>1.561555</td>\n",
       "      <td>5.362447</td>\n",
       "      <td>1.335072</td>\n",
       "      <td>1.831473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2.70604124452, 2.70720754619, 2.89442412667, ...</td>\n",
       "      <td>4.146371</td>\n",
       "      <td>1.767453</td>\n",
       "      <td>5.962685</td>\n",
       "      <td>0.722956</td>\n",
       "      <td>0.701456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              signal        mu     sigma  \\\n",
       "0  [2.41228380224, 2.48438925791, 2.79660720304, ...  5.572910  1.769763   \n",
       "1  [2.27442932107, 2.45701398407, 2.54609334696, ...  3.511228  0.708826   \n",
       "2  [3.14018284117, 3.0731935328, 3.42088457425, 3...  5.659399  1.770733   \n",
       "3  [3.24357931103, 3.43598322601, 3.2900182282, 3...  5.389867  1.561555   \n",
       "4  [2.70604124452, 2.70720754619, 2.89442412667, ...  4.146371  1.767453   \n",
       "\n",
       "   amplitude     slope  constant  \n",
       "0   4.919575  0.948330  1.317692  \n",
       "1   2.645008  1.308834  1.033855  \n",
       "2   4.422514  0.613850  2.511995  \n",
       "3   5.362447  1.335072  1.831473  \n",
       "4   5.962685  0.722956  0.701456  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DatasetN[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for M\n",
    "X_trainM, X_testM, y_trainM, y_testM = train_test_split(signw,m,test_size=0.5)\n",
    "# for A\n",
    "X_trainA, X_testA, y_trainA, y_testA = train_test_split(signw,a,test_size=0.5)\n",
    "#for C\n",
    "X_trainC, X_testC, y_trainC, y_testC = train_test_split(signw,c,test_size=0.5)\n",
    "#for Mu\n",
    "X_trainMu, X_testMu, y_trainMu, y_testMu = train_test_split(signw,mu,test_size=0.5)\n",
    "#for Sigma\n",
    "X_trainS, X_testS, y_trainS, y_testS = train_test_split(signw,sigma,test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wthout Noise in Traning and Noisy data for Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR Prediction Module\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy of SVR for four parameters for a dataset of 1000 values is  -67.1267041095 %\n",
      "Average error rate of SVR for four parameters for a dataset of 1000 values is  0.434404032878\n"
     ]
    }
   ],
   "source": [
    "#for M \n",
    "clf = SVR(C=1.0, epsilon=0.2)\n",
    "clf.fit(X_trainM,y_trainM) \n",
    "SVR(C=1.0, cache_size=2002, coef0=0.0, degree=3, epsilon=0.2, gamma='auto',\n",
    "    kernel='rbf', max_iter=-10, shrinking=True, tol=0.001, verbose=False)\n",
    "P1=clf.predict(X_testM)\n",
    "MC=mean_squared_error(y_testM,P1)\n",
    "y1=clf.score(signw2,y_testM)\n",
    "\n",
    "#for A\n",
    "clf = SVR(C=1.0, epsilon=0.2)\n",
    "clf.fit(X_trainA,y_trainA) \n",
    "SVR(C=1.0, cache_size=2002, coef0=0.0, degree=3, epsilon=0.2, gamma='auto',\n",
    "    kernel='rbf', max_iter=-10, shrinking=True, tol=0.001, verbose=False)\n",
    "P2=clf.predict(X_testA)\n",
    "MC2=mean_squared_error(y_testA,P2)\n",
    "y2=clf.score(signw2,y_testA)\n",
    "\n",
    "#for C\n",
    "clf = SVR(C=1.0, epsilon=0.2)\n",
    "clf.fit(X_trainC,y_trainC) \n",
    "SVR(C=1.0, cache_size=2002, coef0=0.0, degree=3, epsilon=0.2, gamma='auto',\n",
    "    kernel='rbf', max_iter=-10, shrinking=True, tol=0.001, verbose=False)\n",
    "P3=clf.predict(X_testC)\n",
    "MC3=mean_squared_error(y_testC,P3)\n",
    "y3=clf.score(signw2,y_testC)\n",
    "\n",
    "# for Mu\n",
    "clf = SVR(C=1.0, epsilon=0.2)\n",
    "clf.fit(X_trainMu,y_trainMu) \n",
    "SVR(C=1.0, cache_size=2002, coef0=0.0, degree=3, epsilon=0.2, gamma='auto',\n",
    "    kernel='rbf', max_iter=-10, shrinking=True, tol=0.001, verbose=False)\n",
    "P4=clf.predict(X_testMu)\n",
    "MC4=mean_squared_error(y_testMu,P4)\n",
    "y4=clf.score(signw2,y_testMu)\n",
    "\n",
    "#for Sigma\n",
    "\n",
    "clf = SVR(C=1.0, epsilon=0.2)\n",
    "clf.fit(X_trainS,y_trainS) \n",
    "SVR(C=1.0, cache_size=2002, coef0=0.0, degree=3, epsilon=0.2, gamma='auto',\n",
    "    kernel='rbf', max_iter=-10, shrinking=True, tol=0.001, verbose=False)\n",
    "P5=clf.predict(X_testS)\n",
    "MC5=mean_squared_error(y_testS,P3)\n",
    "y5=clf.score(signw2,y_testS)\n",
    "\n",
    "\n",
    "avg=(y1+y2+y3+y4+y5)/5\n",
    "print('Average Accuracy of SVR for four parameters for a dataset of 1000 values is ',avg*100,'%')\n",
    "err=(MC+MC2+MC3+MC4+MC5)/5\n",
    "print('Average error rate of SVR for four parameters for a dataset of 1000 values is ',err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descision forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy of Descision forest regressor for four parameters for a dataset of 1000 values is  -42.4783619063 %\n",
      "Average error of Descision forest regressor for four parameters for a dataset of 1000 values is  0.78667771509\n"
     ]
    }
   ],
   "source": [
    "#for M\n",
    "regr = RandomForestRegressor(max_depth=4, random_state=0)\n",
    "regr.fit(X_trainM, y_trainM)\n",
    "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=3,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=4,\n",
    "           oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "\n",
    "CC=regr.predict(X_testM)\n",
    "RR=mean_squared_error(y_testM,CC)\n",
    "y11=regr.score(signw2,y_testM)\n",
    "\n",
    "#for A\n",
    "regr = RandomForestRegressor(max_depth=4, random_state=0)\n",
    "regr.fit(X_trainA, y_trainA)\n",
    "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=3,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=4,\n",
    "           oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "\n",
    "CC2=regr.predict(X_testA)\n",
    "RR2=mean_squared_error(y_testA,CC2)\n",
    "y22=regr.score(signw2,y_testA)\n",
    "\n",
    "#for C\n",
    "regr = RandomForestRegressor(max_depth=4, random_state=0)\n",
    "regr.fit(X_trainC, y_trainC)\n",
    "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=3,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=4,\n",
    "           oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "\n",
    "CC3=regr.predict(X_testC)\n",
    "RR3=mean_squared_error(y_testC,CC3)\n",
    "y33=regr.score(signw2,y_testC\n",
    "              )\n",
    "#for MU\n",
    "regr = RandomForestRegressor(max_depth=4, random_state=0)\n",
    "regr.fit(X_trainMu, y_trainMu)\n",
    "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=3,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=4,\n",
    "           oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "\n",
    "CC4=regr.predict(X_testMu)\n",
    "RR4=mean_squared_error(y_testMu,CC4)\n",
    "y44=regr.score(signw2,y_testMu)\n",
    "#for Sigma\n",
    "regr = RandomForestRegressor(max_depth=4, random_state=0)\n",
    "regr.fit(X_trainS, y_trainS)\n",
    "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=3,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=4,\n",
    "           oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "\n",
    "CC5=regr.predict(X_testS)\n",
    "RR5=mean_squared_error(y_testS,CC5)\n",
    "y55=regr.score(signw2,y_testS)\n",
    "\n",
    "\n",
    "\n",
    "avg2=(y11+y22+y33+y44+y55)/5\n",
    "print('Average Accuracy of Descision forest regressor for four parameters for a dataset of 1000 values is ',avg2*100,'%')\n",
    "err2=(RR+RR2+RR3+RR4+RR5)/5\n",
    "print('Average error of Descision forest regressor for four parameters for a dataset of 1000 values is ',err2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosted Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy of boosted Descision Tree for four parameters for a dataset of 1000 values is  -67.6926196254 %\n",
      "Average Accuracy of boosted Descision Tree for four parameters for a dataset of 1000 values is  0.341342382613\n"
     ]
    }
   ],
   "source": [
    "#for M\n",
    "regr= AdaBoostRegressor(DecisionTreeRegressor(max_depth=4),\n",
    "                          n_estimators=300)\n",
    "regr.fit(X_trainM, y_trainM)\n",
    "PP=regr.predict(X_testM)\n",
    "g1=regr.score(signw2,y_testM)\n",
    "oo=mean_squared_error(y_testM,PP)\n",
    "\n",
    "#for A\n",
    "\n",
    "regr= AdaBoostRegressor(DecisionTreeRegressor(max_depth=12),\n",
    "                          n_estimators=300)\n",
    "regr.fit(X_trainA, y_trainA)\n",
    "PP2=regr.predict(X_testA)\n",
    "g2=regr.score(signw2,y_testA)\n",
    "oo2=mean_squared_error(y_testA,PP2)\n",
    "\n",
    "#for C\n",
    "\n",
    "regr= AdaBoostRegressor(DecisionTreeRegressor(max_depth=12),\n",
    "                          n_estimators=300)\n",
    "regr.fit(X_trainC, y_trainC)\n",
    "PP3=regr.predict(X_testC)\n",
    "g3=regr.score(signw2,y_testC)\n",
    "oo3=mean_squared_error(y_testC,PP3)\n",
    "\n",
    "#for Mu\n",
    "\n",
    "regr= AdaBoostRegressor(DecisionTreeRegressor(max_depth=12),\n",
    "                          n_estimators=300)\n",
    "regr.fit(X_trainMu, y_trainMu)\n",
    "PP4=regr.predict(X_testMu)\n",
    "g4=regr.score(signw2,y_testMu)\n",
    "oo4=mean_squared_error(y_testMu,PP4)\n",
    "\n",
    "#for Sigma\n",
    "\n",
    "regr= AdaBoostRegressor(DecisionTreeRegressor(max_depth=12),\n",
    "                          n_estimators=300)\n",
    "regr.fit(X_trainS, y_trainS)\n",
    "PP5=regr.predict(X_testS)\n",
    "g5=regr.score(signw2,y_testS)\n",
    "oo5=mean_squared_error(y_testS,PP5)\n",
    "\n",
    "avg3=(g1+g2+g3+g4+g5)/5\n",
    "print('Average Accuracy of boosted Descision Tree for four parameters for a dataset of 1000 values is ',avg3*100,'%')\n",
    "err3=(oo+oo2+oo3+oo4+oo5)/5\n",
    "print('Average Accuracy of boosted Descision Tree for four parameters for a dataset of 1000 values is ',err3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction of Data with noise function added to signals before Traning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#spliiting the DATA\n",
    "\n",
    "#for M\n",
    "X_trainM, X_testM, y_trainM, y_testM = train_test_split(signw2,m2,test_size=0.5)\n",
    "# for A\n",
    "X_trainA, X_testA, y_trainA, y_testA = train_test_split(signw2,a2,test_size=0.5)\n",
    "#for C\n",
    "X_trainC, X_testC, y_trainC, y_testC = train_test_split(signw2,c2,test_size=0.5)\n",
    "#for Mu\n",
    "X_trainMu, X_testMu, y_trainMu, y_testMu = train_test_split(signw2,mu2,test_size=0.5)\n",
    "#for Sigma\n",
    "X_trainS, X_testS, y_trainS, y_testS = train_test_split(signw2,sigma2,test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR prediction module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy of SVR for four parameters for a dataset of 1000 values is  86.5690380806 %\n",
      "Average error rate of SVR for four parameters for a dataset of 1000 values is  0.252490434774\n"
     ]
    }
   ],
   "source": [
    "#for M \n",
    "clf = SVR(C=1.0, epsilon=0.2)\n",
    "clf.fit(X_trainM,y_trainM) \n",
    "SVR(C=1.0, cache_size=2002, coef0=0.0, degree=3, epsilon=0.2, gamma='auto',\n",
    "    kernel='rbf', max_iter=-10, shrinking=True, tol=0.001, verbose=False)\n",
    "P1=clf.predict(X_testM)\n",
    "MCn=mean_squared_error(y_testM,P1)\n",
    "y1n=clf.score(X_testM,y_testM)\n",
    "\n",
    "#for A\n",
    "clf = SVR(C=1.0, epsilon=0.2)\n",
    "clf.fit(X_trainA,y_trainA) \n",
    "SVR(C=1.0, cache_size=2002, coef0=0.0, degree=3, epsilon=0.2, gamma='auto',\n",
    "    kernel='rbf', max_iter=-10, shrinking=True, tol=0.001, verbose=False)\n",
    "P2=clf.predict(X_testA)\n",
    "MC2n=mean_squared_error(y_testA,P2)\n",
    "y2n=clf.score(X_testA,y_testA)\n",
    "\n",
    "#for C\n",
    "clf = SVR(C=1.0, epsilon=0.2)\n",
    "clf.fit(X_trainC,y_trainC) \n",
    "SVR(C=1.0, cache_size=2002, coef0=0.0, degree=3, epsilon=0.2, gamma='auto',\n",
    "    kernel='rbf', max_iter=-10, shrinking=True, tol=0.001, verbose=False)\n",
    "P3=clf.predict(X_testC)\n",
    "MC3n=mean_squared_error(y_testC,P3)\n",
    "y3n=clf.score(X_testC,y_testC)\n",
    "\n",
    "# for Mu\n",
    "clf = SVR(C=1.0, epsilon=0.2)\n",
    "clf.fit(X_trainMu,y_trainMu) \n",
    "SVR(C=1.0, cache_size=2002, coef0=0.0, degree=3, epsilon=0.2, gamma='auto',\n",
    "    kernel='rbf', max_iter=-10, shrinking=True, tol=0.001, verbose=False)\n",
    "P4=clf.predict(X_testMu)\n",
    "MC4n=mean_squared_error(y_testMu,P4)\n",
    "y4n=clf.score(X_testMu,y_testMu)\n",
    "\n",
    "#for Sigma\n",
    "\n",
    "clf = SVR(C=1.0, epsilon=0.2)\n",
    "clf.fit(X_trainS,y_trainS) \n",
    "SVR(C=1.0, cache_size=2002, coef0=0.0, degree=3, epsilon=0.2, gamma='auto',\n",
    "    kernel='rbf', max_iter=-10, shrinking=True, tol=0.001, verbose=False)\n",
    "P5=clf.predict(X_testS)\n",
    "MC5n=mean_squared_error(y_testS,P3)\n",
    "y5n=clf.score(X_testS,y_testS)\n",
    "\n",
    "\n",
    "avg11=(y1n+y2n+y3n+y4n+y5n)/5\n",
    "print('Average Accuracy of SVR for four parameters for a dataset of 1000 values is ',avg11*100,'%')\n",
    "err11=(MCn+MC2n+MC3n+MC4n+MC5n)/5\n",
    "print('Average error rate of SVR for four parameters for a dataset of 1000 values is ',err11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descision forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy of Descision forest regressor for four parameters for a dataset of 1000 values is  63.7971937166 %\n",
      "Average error of Descision forest regressor for four parameters for a dataset of 1000 values is  0.294807041004\n"
     ]
    }
   ],
   "source": [
    "#for M\n",
    "regr = RandomForestRegressor(max_depth=4, random_state=0)\n",
    "regr.fit(X_trainM,y_trainM)\n",
    "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=3,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=4,\n",
    "           oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "\n",
    "CC=regr.predict(X_testM)\n",
    "RRn=mean_squared_error(y_testM,CC)\n",
    "y11n=regr.score(X_testM,y_testM)\n",
    "\n",
    "#for A\n",
    "regr = RandomForestRegressor(max_depth=4, random_state=0)\n",
    "regr.fit(X_trainA, y_trainA)\n",
    "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=3,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=4,\n",
    "           oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "\n",
    "CC2=regr.predict(X_testA)\n",
    "RR2n=mean_squared_error(y_testA,CC2)\n",
    "y22n=regr.score(X_testA,y_testA)\n",
    "\n",
    "#for C\n",
    "regr = RandomForestRegressor(max_depth=4, random_state=0)\n",
    "regr.fit(X_trainC, y_trainC)\n",
    "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=3,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=4,\n",
    "           oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "\n",
    "CC3=regr.predict(X_testC)\n",
    "RR3n=mean_squared_error(y_testC,CC3)\n",
    "y33n=regr.score(X_testC,y_testC)\n",
    "\n",
    "#for MU\n",
    "regr = RandomForestRegressor(max_depth=4, random_state=0)\n",
    "regr.fit(X_trainMu, y_trainMu)\n",
    "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=3,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=4,\n",
    "           oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "\n",
    "CC4=regr.predict(X_testMu)\n",
    "RR4n=mean_squared_error(y_testMu,CC4)\n",
    "y44n=regr.score(X_testMu,y_testMu)\n",
    "\n",
    "#for Sigma\n",
    "regr = RandomForestRegressor(max_depth=4, random_state=0)\n",
    "regr.fit(X_trainS, y_trainS)\n",
    "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=3,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=4,\n",
    "           oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "\n",
    "CC5=regr.predict(X_testS)\n",
    "RR5n=mean_squared_error(y_testS,CC5)\n",
    "y55n=regr.score(X_testS,y_testS)\n",
    "\n",
    "\n",
    "\n",
    "avg22=(y11n+y22n+y33n+y44n+y55n)/5\n",
    "print('Average Accuracy of Descision forest regressor for four parameters for a dataset of 1000 values is ',avg22*100,'%')\n",
    "err22=(RRn+RR2n+RR3n+RR4n+RR5n)/5\n",
    "print('Average error of Descision forest regressor for four parameters for a dataset of 1000 values is ',err22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosted Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy of boosted Descision Tree for four parameters for a dataset of 1000 values is  87.8670217704 %\n",
      "Average Accuracy of boosted Descision Tree for four parameters for a dataset of 1000 values is  0.100793696828\n"
     ]
    }
   ],
   "source": [
    "#for M\n",
    "regr= AdaBoostRegressor(DecisionTreeRegressor(max_depth=4),\n",
    "                          n_estimators=300)\n",
    "regr.fit(X_trainM, y_trainM)\n",
    "PP=regr.predict(X_testM)\n",
    "g1n=regr.score(X_testM,y_testM)\n",
    "oon=mean_squared_error(y_testM,PP)\n",
    "\n",
    "#for A\n",
    "\n",
    "regr= AdaBoostRegressor(DecisionTreeRegressor(max_depth=12),\n",
    "                          n_estimators=300)\n",
    "regr.fit(X_trainA, y_trainA)\n",
    "PP2=regr.predict(X_testA)\n",
    "g2n=regr.score(X_testA,y_testA)\n",
    "oo2n=mean_squared_error(y_testA,PP2)\n",
    "\n",
    "#for C\n",
    "\n",
    "regr= AdaBoostRegressor(DecisionTreeRegressor(max_depth=12),\n",
    "                          n_estimators=300)\n",
    "regr.fit(X_trainC, y_trainC)\n",
    "PP3=regr.predict(X_testC)\n",
    "g3n=regr.score(X_testC,y_testC)\n",
    "oo3n=mean_squared_error(y_testC,PP3)\n",
    "\n",
    "#for Mu\n",
    "\n",
    "regr= AdaBoostRegressor(DecisionTreeRegressor(max_depth=12),\n",
    "                          n_estimators=300)\n",
    "regr.fit(X_trainMu, y_trainMu)\n",
    "PP4=regr.predict(X_testMu)\n",
    "g4n=regr.score(X_testMu,y_testMu)\n",
    "oo4n=mean_squared_error(y_testMu,PP4)\n",
    "\n",
    "#for Sigma\n",
    "\n",
    "regr= AdaBoostRegressor(DecisionTreeRegressor(max_depth=12),\n",
    "                          n_estimators=300)\n",
    "regr.fit(X_trainS, y_trainS)\n",
    "PP5=regr.predict(X_testS)\n",
    "g5n=regr.score(X_testS,y_testS)\n",
    "oo5n=mean_squared_error(y_testS,PP5)\n",
    "\n",
    "avg33=(g1n+g2n+g3n+g4n+g5n)/5\n",
    "print('Average Accuracy of boosted Descision Tree for four parameters for a dataset of 1000 values is ',avg33*100,'%')\n",
    "err33=(oon+oo2n+oo3n+oo4n+oo5n)/5\n",
    "print('Average Accuracy of boosted Descision Tree for four parameters for a dataset of 1000 values is ',err33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "d1 = {\n",
    "      'Algo': ['SVR', 'DFR','BDTR'], \n",
    "      'ERR M': [MC,RR,oo],\n",
    "      'ERR A':[MC2,RR2,oo2],\n",
    "      'ERR C':[MC3,RR3,oo3],\n",
    "      'ERR MU':[MC4,RR4,oo4],\n",
    "      'ERR Sigma': [MC5,RR5,oo5],\n",
    "      'Avg ERR':[err,err2,err3]}\n",
    "\n",
    "dff1 = pd.DataFrame(data=d1)\n",
    "\n",
    "\n",
    "\n",
    "d2 = {\n",
    "      'Algo': ['SVR', 'DFR','BDTR'], \n",
    "      'ERR M': [MCn,RRn,oon],\n",
    "      'ERR A':[MC2n,RR2n,oo2n],\n",
    "      'ERR C':[MC3n,RR3n,oo3n],\n",
    "      'ERR MU':[MC4n,RR4n,oo4n],\n",
    "      'ERR Sigma': [MC5n,RR5n,oo5n],\n",
    "      'Avg ERR':[err11,err22,err33]}\n",
    "\n",
    "dff2 = pd.DataFrame(data=d2)\n",
    "\n",
    "\n",
    "d3 = {\n",
    "      'Algo': ['SVR', 'DFR','BDTR'], \n",
    "      'Auc M': [y1,y11,g1],\n",
    "      'Auc A':[y2,y22,g2],\n",
    "      'Auc c':[y3,y33,g3],\n",
    "      'Auc MU':[y4,y44,g4],\n",
    "      'Auc Sigma': [y5,y55,g5],\n",
    "      'Avg':[avg,avg2,avg3]}\n",
    "\n",
    "dff3 = pd.DataFrame(data=d3)\n",
    "\n",
    "\n",
    "\n",
    "d4 = {\n",
    "      'Algo': ['SVR', 'DFR','BDTR'], \n",
    "      'Auc M': [y1n,y11n,g1n],\n",
    "      'Auc A':[y2n,y22n,g2n],\n",
    "      'Auc C':[y3n,y33n,g3n],\n",
    "      'Auc MU':[y4n,y44n,g4n],\n",
    "      'Auc Sigma': [y5n,y55n,g5n],\n",
    "      'Avg':[avg11,avg22,avg33]}\n",
    "\n",
    "dff4 = pd.DataFrame(data=d4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Rate of the Algorithms\n",
      "\n",
      "For Traning Without Noise\n",
      "\n",
      "   Algo   Avg ERR     ERR A     ERR C     ERR M    ERR MU  ERR Sigma\n",
      "0   SVR  0.434404  0.462194  0.146792  0.019924  0.568395   0.974717\n",
      "1   DFR  0.786678  1.967354  0.384585  0.007111  1.331540   0.242799\n",
      "2  BDTR  0.341342  0.825393  0.139089  0.004868  0.565374   0.171987 \n",
      "\n",
      "For Traning With Noise\n",
      "\n",
      "   Algo   Avg ERR     ERR A     ERR C     ERR M    ERR MU  ERR Sigma\n",
      "0   SVR  0.252490  0.164890  0.189742  0.022905  0.049642   0.835272\n",
      "1   DFR  0.294807  0.929442  0.165716  0.005489  0.200584   0.172804\n",
      "2  BDTR  0.100794  0.316194  0.098009  0.003712  0.034567   0.051487\n"
     ]
    }
   ],
   "source": [
    "print(\"Error Rate of the Algorithms\\n\")\n",
    "print(\"For Traning Without Noise\\n\")\n",
    "\n",
    "print(dff1,'\\n')\n",
    "\n",
    "print(\"For Traning With Noise\\n\")\n",
    "print(dff2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy percentage of the Algorithms\n",
      "\n",
      "For Traning Without Noise\n",
      "\n",
      "   Algo     Auc A     Auc M    Auc MU  Auc Sigma     Auc c       Avg\n",
      "0   SVR -0.662823 -0.641076 -0.890757  -0.662677 -0.499002 -0.671267\n",
      "1   DFR -0.173586 -0.948785 -0.428358  -0.081541 -0.491649 -0.424784\n",
      "2  BDTR -0.401204 -0.950920 -0.914566  -0.355987 -0.761954 -0.676926 \n",
      "\n",
      "For Traning With Noise\n",
      "\n",
      "   Algo     Auc A     Auc C     Auc M    Auc MU  Auc Sigma       Avg\n",
      "0   SVR  0.874081  0.745820  0.923672  0.931561   0.853317  0.865690\n",
      "1   DFR  0.290230  0.778007  0.981708  0.723465   0.416449  0.637972\n",
      "2  BDTR  0.758538  0.868708  0.987631  0.952344   0.826130  0.878670\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy percentage of the Algorithms\\n\") \n",
    "print(\"For Traning Without Noise\\n\")\n",
    "print(dff3,'\\n')\n",
    "print(\"For Traning With Noise\\n\")\n",
    "print(dff4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Form above observation we can conclude that the Boosted Descission Tree is Good For Prediction the parameters of composit function.\n",
    "2. Gaussian curve has negative and positive slops this can be seen in the range set for generation of the parameters.\n",
    "3. The model will not give prediction of parameters when the algorithms are trained without noise being added to input signal before training because the system need to learn the noisy signal and then learn itâ€™s correlation with other parameters and then predict the final values. IE. It is like teaching someone Algebra and ask that person to solve Calculus.The system need the noisy signal in input to train the module else it will be not be able understand the noisy signal when we give it as input when doing validation.There will be no correlation between the type of data the module is trained on and the data that it is getting as input when Testing.\n",
    "4. The module have a very high error rate and negative accuracy percentage this tell us that the module is worse for prediction of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input For Non Noisy Data\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9a80c42320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"input For Non Noisy Data\")\n",
    "plt.plot(signw[3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input For Noisy Data\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9a80c7edd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"input For Noisy Data\")\n",
    "plt.plot(signw2[9])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
